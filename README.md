# INF 554: Machine Learning Labs & Assessment

This repository contains all the lab assignments, a graded assessment, and the final project for the course INF 554: Machine Learning. The projects cover the implementation of fundamental machine learning algorithms from scratch and their application in more complex pipelines.

## Technologies Used

The primary technologies used across these projects include:
* **Python**
* **NumPy**
* **Matplotlib**
* **Scikit-learn**
* **Advanced ML/DL Libraries:** TensorFlow, PyTorch, XGBoost, CatBoost, Transformers

## Project Directory

| # | Topic | Folder Link | Description |
| :-- | :--- | :--- | :--- |
| 1 | **Intro to the ML Pipeline** | [`Lab_1-ml-pipeline-intro/`](./Lab_1-ml-pipeline-intro/) | An introduction to the machine learning pipeline using Ordinary Least Squares (OLS) regression to predict tree growth. |
| 2 | **Regularized Regression** | [`Lab_2-Regularized_Regression/`](./Lab_2-Regularized_Regression/) | Implementation of Ridge (L2) and Lasso (L1) regression to prevent overfitting. Includes hyperparameter tuning. |
| 3 | **Logistic Regression** | [`Lab_3-Logistic_Regression/`](./Lab_3-Logistic_Regression/) | Building a binary classifier from scratch using logistic regression, optimized with gradient descent. |
| 4 | **Support Vector Machines** | [`Lab_4-Support_Vector_Machine/`](./Lab_4-Support_Vector_Machine/) | Implementation of a linear Support Vector Machine (SVM) using hinge loss and sub-gradient descent for classification. |
| 5 | **Decision Trees & Random Forests** | [`Lab_5-Decision_Tree_and_Random_Forest/`](./Lab_5-Decision_Tree_and_Random_Forest/) | Building a Decision Tree classifier from scratch and extending it to a Random Forest ensemble to improve performance. |
| 6 | **Neural Networks** | [`Lab_6-Neural_Networks/`](./Lab_6-Neural_Networks/) | A from-scratch implementation of a simple neural network, covering the forward pass, backpropagation, and parameter updates. |
| 7 | **Principal Component Analysis** | [`Lab_7-Principal_Component_Analysis/`](./Lab_7-Principal_Component_Analysis/) | Implementing PCA for dimensionality reduction by computing the covariance matrix and eigenvectors. |
| 8 | **K-Means Clustering** | [`Lab_8-K-Means_Clustering/`](./Lab_8-K-Means_Clustering/) | An implementation of the K-means algorithm for unsupervised clustering. |
| 9 | **Gaussian Mixture Models** | [`Lab_9-Gaussian_Mixture_Models/`](./Lab_9-Gaussian_Mixture_Models/) | Implementing a probabilistic clustering model using GMMs, trained with the Expectation-Maximization (E-M) algorithm. |
| üéì | **Graded Assessment** | [`Project_1-Income_Prediction_Assessment/`](./Project_1-Income_Prediction_Assessment/) | A project (20% of final grade) to predict income levels from census data by comparing Logistic Regression, SVM, and Random Forest models. |
| üèÜ | **Final Project: Metaclassifiers** | [`Project_2-Metaclassifier-Final_Project/`](./Project_2-Metaclassifier-Final_Project/) | An advanced classification project comparing metaclassifiers (XGBoost, CatBoost, LSTM, TabNet) with features from NLP models like RoBERTa and Gemini. |
